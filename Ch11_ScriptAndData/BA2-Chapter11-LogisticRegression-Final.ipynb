{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import necessary base packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Attrition  Yrs_Exp Work_Challenging Work_Envir Compensation Tech_Exper\n",
      "0        Yes      2.5               No        Low          Low  Excellent\n",
      "1         No      2.0              Yes  Excellent    Excellent  Excellent\n",
      "2         No      2.5              Yes  Excellent          Low  Excellent\n",
      "3        Yes      2.0               No  Excellent          Low  Excellent\n",
      "4         No      2.0              Yes        Low          Low        Low\n",
      "5        Yes      2.0               No        Low          Low  Excellent\n",
      "6         No      2.0               No  Excellent    Excellent        Low\n",
      "7        Yes      2.5               No        Low    Excellent  Excellent\n",
      "8        Yes      2.0               No  Excellent          Low  Excellent\n",
      "9        Yes      3.0              Yes        Low    Excellent  Excellent\n",
      "10       Yes      3.5               No  Excellent          Low  Excellent\n",
      "11        No      3.0              Yes  Excellent    Excellent  Excellent\n",
      "12        No      2.0              Yes  Excellent          Low  Excellent\n",
      "13        No      2.0              Yes  Excellent    Excellent  Excellent\n",
      "14        No      2.5              Yes        Low    Excellent        Low\n",
      "15        No      2.0              Yes  Excellent    Excellent        Low\n",
      "16       Yes      2.5               No        Low          Low  Excellent\n",
      "17        No      4.5              Yes  Excellent    Excellent  Excellent\n",
      "18       Yes      4.0               No  Excellent          Low  Excellent\n",
      "19       Yes      4.0              Yes        Low    Excellent  Excellent\n",
      "20       Yes      4.5               No        Low          Low  Excellent\n",
      "21        No      4.5               No  Excellent    Excellent  Excellent\n",
      "22       Yes      4.0               No  Excellent          Low  Excellent\n",
      "23       Yes      4.0               No        Low          Low  Excellent\n",
      "24        No      4.5              Yes  Excellent          Low  Excellent\n",
      "25        No      4.5               No  Excellent    Excellent  Excellent\n",
      "26        No      4.0              Yes  Excellent          Low  Excellent\n",
      "27       Yes      4.0               No        Low          Low  Excellent\n",
      "28       Yes      4.5               No        Low          Low  Excellent\n",
      "29        No      4.0               No  Excellent          Low        Low\n",
      "30       Yes      4.0               No        Low          Low  Excellent\n",
      "31       Yes      4.5               No        Low          Low  Excellent\n",
      "32       Yes      5.0               No        Low          Low  Excellent\n",
      "33        No      5.0              Yes  Excellent    Excellent  Excellent\n",
      "34       Yes      4.5              Yes        Low          Low  Excellent\n",
      "35       Yes      5.0              Yes        Low          Low  Excellent\n",
      "36        No      5.0              Yes  Excellent    Excellent  Excellent\n",
      "37       Yes      5.0               No        Low          Low  Excellent\n",
      "38       Yes      5.0               No        Low          Low  Excellent\n",
      "39       Yes      5.0              Yes        Low          Low        Low\n",
      "40        No      2.5              Yes  Excellent          Low        Low\n",
      "41       Yes      2.0               No        Low          Low  Excellent\n",
      "42        No      3.5              Yes        Low    Excellent  Excellent\n",
      "43       Yes      2.5               No        Low          Low  Excellent\n",
      "44       Yes      3.0               No  Excellent          Low  Excellent\n",
      "45        No      2.0              Yes        Low    Excellent  Excellent\n",
      "46        No      4.0              Yes  Excellent    Excellent  Excellent\n",
      "47        No      4.5               No  Excellent          Low        Low\n",
      "48       Yes      5.0               No  Excellent    Excellent  Excellent\n",
      "49        No      5.0               No  Excellent    Excellent  Excellent\n",
      "50       Yes      2.0              Yes  Excellent    Excellent  Excellent\n",
      "51        No      4.0              Yes  Excellent    Excellent  Excellent\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "attri_data = pd.read_csv('E:/Book_Revision/attri_data_10.txt', sep=',', header=0)\n",
    "print(attri_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 6 columns):\n",
      "Attrition           52 non-null object\n",
      "Yrs_Exp             52 non-null float64\n",
      "Work_Challenging    52 non-null object\n",
      "Work_Envir          52 non-null object\n",
      "Compensation        52 non-null object\n",
      "Tech_Exper          52 non-null object\n",
      "dtypes: float64(1), object(5)\n",
      "memory usage: 2.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#get full information on attri_data dataframe\n",
    "X=attri_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#making a copy of the attri_data dataframe\n",
    "X = attri_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition</th>\n",
       "      <th>Yrs_Exp</th>\n",
       "      <th>Work_Challenging</th>\n",
       "      <th>Work_Envir</th>\n",
       "      <th>Compensation</th>\n",
       "      <th>Tech_Exper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attrition  Yrs_Exp  Work_Challenging  Work_Envir  Compensation  Tech_Exper\n",
       "0          1      2.5                 0           1             1           0\n",
       "1          0      2.0                 1           0             0           0\n",
       "2          0      2.5                 1           0             1           0\n",
       "3          1      2.0                 0           0             1           0\n",
       "4          0      2.0                 1           1             1           1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labelEncode categorical variables out of the predictor variables \n",
    "#This is required in order that the LogisticRegression model \n",
    "#builder recognizes the values of these predictors\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "X[['Attrition','Work_Challenging','Work_Envir','Compensation',\n",
    "   'Tech_Exper']]=X[['Attrition','Work_Challenging','Work_Envir',\n",
    "   'Compensation','Tech_Exper']].apply(le.fit_transform)\n",
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the dataframe with response variables (y)\n",
    "#and another with only the predictor #variables (X)\n",
    "y = X.Attrition\n",
    "X = X[X.columns[1::]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the dataset into two separate sets viz. training set\n",
    "#and test set manually \n",
    "#training set for generating the model\n",
    "#test set for validating the model generated\n",
    "train_samp = (40)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "    train_size=train_samp, test_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logist_regre = LogisticRegression(random_state = 0, penalty = 'l2', \n",
    "    solver = 'lbfgs', multi_class = 'multinomial', \n",
    "    max_iter = 500).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity with L2 penalty: 0.00%\n",
      "Test score with L2 penalty: 0.6667\n"
     ]
    }
   ],
   "source": [
    "# Using logist_regre model\n",
    "sparsity_1 = np.mean(logist_regre.coef_ == 0) * 100\n",
    "score_1 = logist_regre.score(X_test, y_test)\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity_1)\n",
    "print(\"Test score with L2 penalty: %.4f\" % score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.50      0.60         6\n",
      "          1       0.62      0.83      0.71         6\n",
      "\n",
      "avg / total       0.69      0.67      0.66        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = logist_regre.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 3]\n",
      " [1 5]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(sm.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Even though we did not get high accuracy above, if we iterate\n",
    "#the same exercise we may not get the same accuracy, we \n",
    "#may get higher or lower accuracy\n",
    "#We need to set the random seed using np if we want\n",
    "#the same result to be output each time we run the step\n",
    "#As we know from the discussion on the R Section, which\n",
    "#we can validate through the model statistics in\n",
    "#Python also, we know that Yrs_Exp is not significant\n",
    "#to the model.  Let us remove the Yrs_Exp from the dataframe\n",
    "#and generate the model and check for the accuracy\n",
    "Z = X.drop(['Yrs_Exp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split the dataset into two separate sets viz. training set\n",
    "#and test set manually \n",
    "#training set for generating the model\n",
    "#test set for validating the model generated\n",
    "train_samp = (40)\n",
    "from sklearn.model_selection import train_test_split\n",
    "Z_train, Z_test, y_train, y_test = train_test_split(Z, y, \n",
    "    train_size=train_samp, test_size=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logist_regre = LogisticRegression(random_state = 0, penalty = 'l2', \n",
    "    solver = 'lbfgs', multi_class = 'multinomial', \n",
    "    max_iter = 500).fit(Z_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity with L2 penalty: 0.00%\n",
      "Test score with L2 penalty: 0.9167\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "# Using logist_regre model\n",
    "sparsity_1 = np.mean(logist_regre.coef_ == 0) * 100\n",
    "score_1 = logist_regre.score(Z_test, y_test)\n",
    "# print('Best C % .4f' % clf.C_)\n",
    "print(\"Sparsity with L2 penalty: %.2f%%\" % sparsity_1)\n",
    "print(\"Test score with L2 penalty: %.4f\" % score_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.86      0.92         7\n",
      "          1       0.83      1.00      0.91         5\n",
      "\n",
      "avg / total       0.93      0.92      0.92        12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted = logist_regre.predict(Z_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 1]\n",
      " [0 5]]\n"
     ]
    }
   ],
   "source": [
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(sm.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75862672,  0.96860213,  0.63232032, -0.84379994]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print logistic regression coefficients\n",
    "logist_regre.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "#Seabold, Skipper, and Josef Perktold. “statsmodels: Econometric and \n",
    "#statistical modeling with python.” Proceedings of the 9th Python in \n",
    "#Science Conference. 2010. Thanks to Statsmodels\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import logit\n",
    "logit_mod = sm.Logit(y_train, Z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.262090\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>Attrition</td>    <th>  No. Observations:  </th>  <td>    40</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>               <td>Logit</td>      <th>  Df Residuals:      </th>  <td>    36</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>          <td>Sun, 14 Aug 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.6156</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>              <td>11:44:08</td>     <th>  Log-Likelihood:    </th> <td> -10.484</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>           <td>True</td>       <th>  LL-Null:           </th> <td> -27.274</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th> </th>                      <td> </td>        <th>  LLR p-value:       </th> <td>2.428e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>            <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Work_Challenging</th> <td>   -3.0228</td> <td>    1.287</td> <td>   -2.349</td> <td> 0.019</td> <td>   -5.545</td> <td>   -0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Work_Envir</th>       <td>    4.1816</td> <td>    1.637</td> <td>    2.554</td> <td> 0.011</td> <td>    0.973</td> <td>    7.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Compensation</th>     <td>    2.2552</td> <td>    1.138</td> <td>    1.982</td> <td> 0.047</td> <td>    0.025</td> <td>    4.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Tech_Exper</th>       <td>   -3.9206</td> <td>    1.735</td> <td>   -2.259</td> <td> 0.024</td> <td>   -7.322</td> <td>   -0.519</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              Attrition   No. Observations:                   40\n",
       "Model:                          Logit   Df Residuals:                       36\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Sun, 14 Aug 2022   Pseudo R-squ.:                  0.6156\n",
       "Time:                        11:44:08   Log-Likelihood:                -10.484\n",
       "converged:                       True   LL-Null:                       -27.274\n",
       "                                        LLR p-value:                 2.428e-07\n",
       "====================================================================================\n",
       "                       coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------\n",
       "Work_Challenging    -3.0228      1.287     -2.349      0.019      -5.545      -0.501\n",
       "Work_Envir           4.1816      1.637      2.554      0.011       0.973       7.390\n",
       "Compensation         2.2552      1.138      1.982      0.047       0.025       4.485\n",
       "Tech_Exper          -3.9206      1.735     -2.259      0.024      -7.322      -0.519\n",
       "====================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_resi = logit_mod.fit()\n",
    "logit_resi.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.92      0.90        24\n",
      "          1       0.93      0.89      0.91        28\n",
      "\n",
      "avg / total       0.90      0.90      0.90        52\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Here, we are applying the model to the full data\n",
    "#set (excluding Yrs_Exp to predict on the full dataset\n",
    "predicted_full = logist_regre.predict(Z)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y, predicted_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22  2]\n",
      " [ 3 25]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrizx of the prediction on the\n",
    "#full data set (except Yrs_Exp)\n",
    "import sklearn.metrics as sm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(sm.confusion_matrix(y, predicted_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work_Challenging   -2.349154\n",
      "Work_Envir          2.554033\n",
      "Compensation        1.981947\n",
      "Tech_Exper         -2.259078\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(logit_resi.tvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Work_Challenging    0.018816\n",
      "Work_Envir          0.010648\n",
      "Compensation        0.047485\n",
      "Tech_Exper          0.023879\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(logit_resi.pvalues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
